{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of clicks prediction\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mosal/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.metrics.scorer module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from io import StringIO\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostRegressor,  BaggingRegressor, ExtraTreesRegressor, GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MaxAbsScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.base import clone, TransformerMixin\n",
    "from sklearn.metrics.scorer import make_scorer\n",
    "from sklearn.model_selection import KFold\n",
    "import time\n",
    "import pickle\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "import xgboost\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's read our cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content_score</th>\n",
       "      <th>n_images</th>\n",
       "      <th>distance_to_center</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>stars</th>\n",
       "      <th>n_reviews</th>\n",
       "      <th>avg_rank</th>\n",
       "      <th>avg_price</th>\n",
       "      <th>avg_saving_percent</th>\n",
       "      <th>n_clicks</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1199.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>861.0</td>\n",
       "      <td>17.550</td>\n",
       "      <td>81.64</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12585.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4371.0</td>\n",
       "      <td>17.383</td>\n",
       "      <td>189.38</td>\n",
       "      <td>28.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>751.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3291.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3084.0</td>\n",
       "      <td>7.000</td>\n",
       "      <td>72.16</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>66.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>288.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>603.0</td>\n",
       "      <td>12.564</td>\n",
       "      <td>173.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>73.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>58.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1249.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1683.0</td>\n",
       "      <td>18.391</td>\n",
       "      <td>96.70</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   content_score  n_images  distance_to_center  avg_rating  stars  n_reviews  \\\n",
       "0           70.0       2.0              1199.0        77.0    4.0      861.0   \n",
       "1           67.0       3.0             12585.0        90.0    4.0     4371.0   \n",
       "2           59.0       8.0              3291.0        73.0    2.0     3084.0   \n",
       "3           66.0       1.0               288.0        80.0    0.0      603.0   \n",
       "4           58.0       2.0              1249.0        87.0    0.0     1683.0   \n",
       "\n",
       "   avg_rank  avg_price  avg_saving_percent  n_clicks  count  \n",
       "0    17.550      81.64                18.0       0.0   80.0  \n",
       "1    17.383     189.38                28.0       4.0  751.0  \n",
       "2     7.000      72.16                 2.0       4.0    5.0  \n",
       "3    12.564     173.25                 0.0      10.0   73.0  \n",
       "4    18.391      96.70                 0.0       0.0   68.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hotel_data = pd.read_csv('cleaned.csv')\n",
    "hotel_data = hotel_data.drop(columns = ['hotel_id'])\n",
    "hotel_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First let's create our X and y for the model\n",
    "initial_model_data = hotel_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's split the data into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data):\n",
    "    \"\"\"\n",
    "    Split the data into X and y and then into train and test set\n",
    "    \n",
    "    input:\n",
    "    -----\n",
    "    data: dataframe \n",
    "    \n",
    "    returns:\n",
    "    --------\n",
    "    X_train,X_test,y_train,y_test\n",
    "    \"\"\"\n",
    "    y = data['n_clicks']\n",
    "    X = data.drop(columns = ['n_clicks'])\n",
    "    \n",
    "    (X_train, X_test, y_train, y_test)  = train_test_split(X,y,test_size = 0.2, random_state = 2020)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_0, X_test_0, y_train_0, y_test_0 = split_data(initial_model_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To create a pipeline we need to specify that columns we want to prepoces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['content_score',\n",
       " 'n_images',\n",
       " 'distance_to_center',\n",
       " 'avg_rating',\n",
       " 'stars',\n",
       " 'n_reviews',\n",
       " 'avg_rank',\n",
       " 'avg_price',\n",
       " 'avg_saving_percent',\n",
       " 'count']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_cols = list(X_train_0.columns)\n",
    "numerical_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_transformer = Pipeline(steps = [('imputer',SimpleImputer()),\n",
    "                                         ('scaler',StandardScaler())                                                     \n",
    "                                        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(transformers = [('num',numerical_transformer,numerical_cols)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline: Linear Model :\n",
    "Linear models are fast, and easy to build and interpret, we will start with Ridge models which apply linear regression with regularization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge=  RidgeCV(alphas=[1e-3, 1e-2, 1e-1,0.2,0.4,0.6,0.8, 1])\n",
    "reg_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('regressor',ridge)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model score on training set =  0.11949700423537135\n",
      "model score on test set =  0.11691446442852249\n",
      "elapsed time =  0.48073792457580566\n",
      "MSE =  28.51637863610852\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "reg_pipeline.fit(X_train_0,y_train_0)\n",
    "print('model score on training set = ',reg_pipeline.score(X_train_0, y_train_0))\n",
    "print('model score on test set = ',reg_pipeline.score(X_test_0, y_test_0))\n",
    "y_pred_0 = reg_pipeline.predict(X_test_0)\n",
    "elapsed_time = time.time() - start_time\n",
    "print('elapsed time = ',elapsed_time )\n",
    "print('MSE = ',mean_squared_error(y_test_0, y_pred_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model,X_test,y_test):\n",
    "    \"\"\"\n",
    "    evaluate the performance of a given model on the X_test\n",
    "    \n",
    "    input:\n",
    "    -----\n",
    "    \n",
    "    model : fitted model\n",
    "    X_test : dataframe\n",
    "    y_test : dataframe\n",
    "    \n",
    "        \"\"\"\n",
    "\n",
    "    start_time = time.time()\n",
    "    print('model score on test set = ',model.score(X_test, y_test))\n",
    "    y_pred = model.predict(X_test)\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print('elapsed time = ',elapsed_time )\n",
    "    print('MSE = ',mean_squared_error(y_test, y_pred))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The model is fas but it has very poor performance. Could we improve the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's create a function for the pipeline since we will need many times later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pipeline(X_train,y_train, model):\n",
    "    \n",
    "    \"\"\"\n",
    "    Create a pipeline for preprocessing and modeling\n",
    "    \n",
    "    inputs:\n",
    "    -----\n",
    "    X_train: dataframe\n",
    "    model : sklearn model\n",
    "    \"\"\"\n",
    "    \n",
    "    numerical_cols = list(X_train.columns)\n",
    "    numerical_transformer = Pipeline(steps = [('imputer',SimpleImputer()),\n",
    "                                         ('scaler',StandardScaler())                                                     \n",
    "                                        ])\n",
    "    preprocessor = ColumnTransformer(transformers = [('num',numerical_transformer,numerical_cols)])\n",
    "    reg_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('regressor', model)])\n",
    "    reg_pipeline.fit(X_train,y_train)\n",
    "    \n",
    "    return reg_pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One fast way to improve the peformance is to create more meaningful feature. For example, we have the avg_price and the avg_saving_percent, but often people think in terms of how much money the save. Therefore, we can create new feature, let's call it avg_saving_cash by multiplying avg_price and avg_saving_percent\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we will create a copy of the original dataset\n",
    "hotel_data_fengineering = hotel_data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now let's create our new feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel_data_fengineering['avg_saving_cash'] =hotel_data_fengineering['avg_price']*hotel_data_fengineering['avg_saving_percent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's drop these columns to avoid colinearlity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content_score</th>\n",
       "      <th>n_images</th>\n",
       "      <th>distance_to_center</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>stars</th>\n",
       "      <th>n_reviews</th>\n",
       "      <th>avg_rank</th>\n",
       "      <th>n_clicks</th>\n",
       "      <th>count</th>\n",
       "      <th>avg_saving_cash</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1199.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>861.0</td>\n",
       "      <td>17.550</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1469.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12585.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4371.0</td>\n",
       "      <td>17.383</td>\n",
       "      <td>4.0</td>\n",
       "      <td>751.0</td>\n",
       "      <td>5302.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3291.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3084.0</td>\n",
       "      <td>7.000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>144.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>66.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>288.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>603.0</td>\n",
       "      <td>12.564</td>\n",
       "      <td>10.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>58.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1249.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1683.0</td>\n",
       "      <td>18.391</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372925</th>\n",
       "      <td>48.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>469.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372926</th>\n",
       "      <td>42.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>689.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>14.174</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>466.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372927</th>\n",
       "      <td>70.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1424.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.211</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372928</th>\n",
       "      <td>42.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>20.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372929</th>\n",
       "      <td>36.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.387</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>372930 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        content_score  n_images  distance_to_center  avg_rating  stars  \\\n",
       "0                70.0       2.0              1199.0        77.0    4.0   \n",
       "1                67.0       3.0             12585.0        90.0    4.0   \n",
       "2                59.0       8.0              3291.0        73.0    2.0   \n",
       "3                66.0       1.0               288.0        80.0    0.0   \n",
       "4                58.0       2.0              1249.0        87.0    0.0   \n",
       "...               ...       ...                 ...         ...    ...   \n",
       "372925           48.0       1.0               469.0        83.0    0.0   \n",
       "372926           42.0       0.0               689.0        83.0    0.0   \n",
       "372927           70.0       1.0              1424.0        83.0    0.0   \n",
       "372928           42.0       0.0               164.0        84.0    0.0   \n",
       "372929           36.0       1.0                 0.0        83.0    0.0   \n",
       "\n",
       "        n_reviews  avg_rank  n_clicks  count  avg_saving_cash  \n",
       "0           861.0    17.550       0.0   80.0          1469.52  \n",
       "1          4371.0    17.383       4.0  751.0          5302.64  \n",
       "2          3084.0     7.000       4.0    5.0           144.32  \n",
       "3           603.0    12.564      10.0   73.0             0.00  \n",
       "4          1683.0    18.391       0.0   68.0             0.00  \n",
       "...           ...       ...       ...    ...              ...  \n",
       "372925        0.0    21.000       0.0   16.0             0.00  \n",
       "372926       72.0    14.174       0.0   66.0           466.24  \n",
       "372927        0.0    16.211       4.0   11.0             0.00  \n",
       "372928      222.0    20.000       0.0    5.0             0.00  \n",
       "372929        0.0    20.387       0.0   32.0             0.00  \n",
       "\n",
       "[372930 rows x 10 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hotel_data_fengineering = hotel_data_fengineering.drop(columns = ['avg_price','avg_saving_percent'])\n",
    "hotel_data_fengineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's split the data\n",
    "X_train_1, X_test_1, y_train_1, y_test_1 = split_data(hotel_data_fengineering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a pipleline\n",
    "ridge=  RidgeCV(alphas=[1e-3, 1e-2, 1e-1,0.2,0.4,0.6,0.8, 1])\n",
    "reg_pipeline2 = create_pipeline(X_train_1,y_train_1,ridge )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model score on test set =  0.12239552717826341\n",
      "elapsed time =  0.0450739860534668\n",
      "MSE =  28.339385520035417\n"
     ]
    }
   ],
   "source": [
    "# evaluating the performance of the model\n",
    "evaluate_model(reg_pipeline2,X_test_1,y_test_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Indeed we notice some improvement for the model which has the new features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing other Models:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now test several models including SGD, Gradient Boost, Random Forest and XGB and evaluate them base on mean squared error and performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_models():\n",
    "    \"\"\"\n",
    "    creates regression a selected models with the defualt values\n",
    "    \n",
    "    input :\n",
    "    ----\n",
    "    None\n",
    "    returns:\n",
    "    -------\n",
    "    Two lists, one for models and the second is for the name of the models\n",
    "    \"\"\"\n",
    "    sgd = SGDRegressor(random_state=2020)\n",
    "    grad = GradientBoostingRegressor(random_state=2020)\n",
    "    rf =RandomForestRegressor(random_state=2020)\n",
    "    xgb = XGBRegressor()\n",
    "    regressors = [sgd, grad,rf,xgb]\n",
    "    regressors_names = ['SGDRegressor','Gradient Boost','Random Forest','xgb']\n",
    "    return  regressors,regressors_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's test these models and evaluate their performance\n",
    "\n",
    "    \n",
    "regressors,regressor_names = build_models()\n",
    "\n",
    "for regressor,regressor_name in zip(regressors,regressor_names):\n",
    "    regressor_pipeline = Pipeline(steps = [('preprocessor',preprocessor),\n",
    "                                      ('regressor',regressor)])\n",
    "    start_time = time.time()\n",
    "    regressor_pipeline.fit(X_train,y_train)\n",
    "    print('Results for ',regressor_name)\n",
    "    print('Training score = ',regressor_pipeline.score(X_train,y_train))\n",
    "    print('Test score = ',regressor_pipeline.score(X_test,y_test))\n",
    "    y_pred = regressor_pipeline.predict(X_test)\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print('elapsed time = ',elapsed_time )\n",
    "    print('MSE = ',mean_squared_error(y_test, y_pred))\n",
    "    print('______________________________________________________')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### According to this results,we have the following observations :\n",
    "- Linear Regression SGDRegressor have the fastest models but also have the lowest accuracy\n",
    "- Gradient Boost model has the a bias issues, while random forest has a variance issues.\n",
    "- XGBRegressor seems to be the most promsing in terms of MSE. We will adopt this model and try to fine tune the paramters to improve the mse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Improvements : Hyperparamters optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's create our X_train and X_test since it has it's own cross-validation.\n",
    "data_train = xgboost.DMatrix(X_train, label=y_train)\n",
    "data_test = xgboost.DMatrix(X_test, label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will now create our initial set of paramters, which are the defual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    # Parameters that we are going to tune.\n",
    "    'max_depth':6,\n",
    "    'min_child_weight': 1,\n",
    "    'eta':.3,\n",
    "    'subsample': 1,\n",
    "    'colsample_bytree': 1,\n",
    "    # Other parameters\n",
    "    'objective':'reg:squarederror',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['eval_metric'] = \"rmse\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_boost_round = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgboost.train(\n",
    "    params,\n",
    "    data_train,\n",
    "    num_boost_round=num_boost_round,\n",
    "    evals=[(data_test, \"Test\")],\n",
    "    early_stopping_rounds=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tunning paramters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters max_depth and min_child_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch_params = [\n",
    "    (max_depth, min_child_weight)\n",
    "    for max_depth in range(6,10)\n",
    "    for min_child_weight in range(1,4)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define initial best params and MAE\n",
    "min_rmse = float(\"Inf\")\n",
    "best_params = None\n",
    "for max_depth, min_child_weight in gridsearch_params:\n",
    "    print(\"CV with max_depth={}, min_child_weight={}\".format(\n",
    "                             max_depth,\n",
    "                             min_child_weight))\n",
    "    # Update our parameters\n",
    "    params['max_depth'] = max_depth\n",
    "    params['min_child_weight'] = min_child_weight\n",
    "    # Run CV\n",
    "    cv_results = xgboost.cv(\n",
    "        params,\n",
    "        data_train,\n",
    "        num_boost_round=num_boost_round,\n",
    "        seed=2020,\n",
    "        nfold=10,\n",
    "        metrics={'rmse'},\n",
    "        early_stopping_rounds=20\n",
    "    )\n",
    "    # Update best rmse\n",
    "    mean_rmse = cv_results['test-rmse-mean'].min()\n",
    "    boost_rounds = cv_results['test-rmse-mean'].argmin()\n",
    "    print(\"\\trmse {} for {} rounds\".format(mean_rmse, boost_rounds))\n",
    "    if mean_rmse < min_rmse:\n",
    "        min_rmse = mean_rmse\n",
    "        best_params = (max_depth,min_child_weight)\n",
    "print(\"Best params: {}, {}, RMSE: {}\".format(best_params[0], best_params[1], min_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['max_depth'] = 4\n",
    "params['min_child_weight'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters subsample and colsample_bytree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch_params = [\n",
    "    (subsample, colsample)\n",
    "    for subsample in [i/10. for i in range(7,11)]\n",
    "    for colsample in [i/10. for i in range(7,11)]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_rmse = float(\"Inf\")\n",
    "best_params = None\n",
    "# We start by the largest values and go down to the smallest\n",
    "for subsample, colsample in reversed(gridsearch_params):\n",
    "    print(\"CV with subsample={}, colsample={}\".format(\n",
    "                             subsample,\n",
    "                             colsample))\n",
    "    # We update our parameters\n",
    "    params['subsample'] = subsample\n",
    "    params['colsample_bytree'] = colsample\n",
    "    # Run CV\n",
    "    cv_results = xgboost.cv(\n",
    "        params,\n",
    "        data_train,\n",
    "        num_boost_round=num_boost_round,\n",
    "        seed=2020,\n",
    "        nfold=1010,\n",
    "        metrics={'rmse'},\n",
    "        early_stopping_rounds=10\n",
    "    )\n",
    "    # Update best score\n",
    "    mean_mae = cv_results['test-rmse-mean'].min()\n",
    "    boost_rounds = cv_results['test-rmse-mean'].argmin()\n",
    "    print(\"\\trmse {} for {} rounds\".format(mean_mae, boost_rounds))\n",
    "    if mean_mae < min_mae:\n",
    "        min_mae = mean_mae\n",
    "        best_params = (subsample,colsample)\n",
    "print(\"Best params: {}, {}, rmse: {}\".format(best_params[0], best_params[1], min_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['subsample'] = 0.9\n",
    "params['colsample_bytree'] = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameter ETA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "# This can take some time…\n",
    "min_mae = float(\"Inf\")\n",
    "best_params = None\n",
    "for eta in [.3, .2, .1, .05, .01, .005]:\n",
    "    print(\"CV with eta={}\".format(eta))\n",
    "    # We update our parameters\n",
    "    params['eta'] = eta\n",
    "    # Run and time CV\n",
    "    %time cv_results = xgboost.cv(params,dtrain,num_boost_round=num_boost_round,seed=42,nfold=5,metrics=['rmse'],early_stopping_rounds=10)\n",
    "    # Update best score\n",
    "    mean_mae = cv_results['test-rmse-mean'].min()\n",
    "    boost_rounds = cv_results['test-rmse-mean'].argmin()\n",
    "    print(\"\\tMAE {} for {} rounds\\n\".format(mean_mae, boost_rounds))\n",
    "    if mean_mae < min_mae:\n",
    "        min_mae = mean_mae\n",
    "        best_params = eta\n",
    "print(\"Best params: {}, MAE: {}\".format(best_params, min_mae))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['eta'] = .03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at out final parameters\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = xgboost.cv(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=num_boost_round,\n",
    "    seed=42,\n",
    "    nfold=5,\n",
    "    metrics={'rmse'},\n",
    "    early_stopping_rounds=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results['test-rmse-mean'].min()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training the final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgboost.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=num_boost_round,\n",
    "    evals=[(dtest, \"Test\")],\n",
    "    early_stopping_rounds=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_boost_round = model.best_iteration + 1\n",
    "best_model = xgboost.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=num_boost_round,\n",
    "    evals=[(dtest, \"Test\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(best_model.predict(dtest), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
