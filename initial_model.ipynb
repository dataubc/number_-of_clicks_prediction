{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of clicks prediction\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from io import StringIO\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostRegressor,  BaggingRegressor, ExtraTreesRegressor, GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MaxAbsScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.base import clone, TransformerMixin\n",
    "from sklearn.metrics.scorer import make_scorer\n",
    "from sklearn.model_selection import KFold\n",
    "import time\n",
    "import pickle\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "import xgboost\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's read our cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hotel_id</th>\n",
       "      <th>content_score</th>\n",
       "      <th>n_images</th>\n",
       "      <th>distance_to_center</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>stars</th>\n",
       "      <th>n_reviews</th>\n",
       "      <th>avg_rank</th>\n",
       "      <th>avg_price</th>\n",
       "      <th>avg_saving_percent</th>\n",
       "      <th>n_clicks</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.767406e+10</td>\n",
       "      <td>70.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1199.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>861.0</td>\n",
       "      <td>17.550</td>\n",
       "      <td>81.64</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.768889e+10</td>\n",
       "      <td>67.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12585.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4371.0</td>\n",
       "      <td>17.383</td>\n",
       "      <td>189.38</td>\n",
       "      <td>28.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>751.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.824279e+10</td>\n",
       "      <td>59.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3291.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3084.0</td>\n",
       "      <td>7.000</td>\n",
       "      <td>72.16</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.833438e+10</td>\n",
       "      <td>66.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>288.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>603.0</td>\n",
       "      <td>12.564</td>\n",
       "      <td>173.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>73.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9.839326e+10</td>\n",
       "      <td>58.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1249.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1683.0</td>\n",
       "      <td>18.391</td>\n",
       "      <td>96.70</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       hotel_id  content_score  n_images  distance_to_center  avg_rating  \\\n",
       "0  9.767406e+10           70.0       2.0              1199.0        77.0   \n",
       "1  9.768889e+10           67.0       3.0             12585.0        90.0   \n",
       "3  9.824279e+10           59.0       8.0              3291.0        73.0   \n",
       "4  9.833438e+10           66.0       1.0               288.0        80.0   \n",
       "5  9.839326e+10           58.0       2.0              1249.0        87.0   \n",
       "\n",
       "   stars  n_reviews  avg_rank  avg_price  avg_saving_percent  n_clicks  count  \n",
       "0    4.0      861.0    17.550      81.64                18.0       0.0   80.0  \n",
       "1    4.0     4371.0    17.383     189.38                28.0       4.0  751.0  \n",
       "3    2.0     3084.0     7.000      72.16                 2.0       4.0    5.0  \n",
       "4    0.0      603.0    12.564     173.25                 0.0      10.0   73.0  \n",
       "5    0.0     1683.0    18.391      96.70                 0.0       0.0   68.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hotel_data = pd.read_pickle('cleaned.pkl')\n",
    "hotel_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experimenting with all columns from the encoding of the city_id columns proved to be very slow, so for now I am dropping those columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hotel_data = hotel_data.iloc[:,:10]\n",
    "# hotel_data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First let's create our X and y for the model\n",
    "initial_model_data = hotel_data.copy()\n",
    "\n",
    "y_inital_model= initial_model_data['n_clicks']\n",
    "X_initial_model = initial_model_data.drop(columns = ['n_clicks'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's split the data into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_initial_model,y_inital_model,test_size = 0.2, random_state = 2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To create a pipeline we need to specify that columns we want to prepoces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = list(X_train.columns)\n",
    "numerical_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_transformer = Pipeline(steps = [('imputer',SimpleImputer()),\n",
    "                                         ('scaler',StandardScaler())                                                     \n",
    "                                        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(transformers = [('num',numerical_transformer,numerical_cols)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline: Linear Model :\n",
    "Linear models are fast, and easy to build and interpret, we will start with Ridge models which apply linear regression with regularization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('regressor', RidgeCV(alphas=[1e-3, 1e-2, 1e-1,0.2,0.4,0.6,0.8, 1]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "reg.fit(X_train,y_train)\n",
    "print('model score on training set = ',reg.score(X_train, y_train))\n",
    "print('model score on test set = ',reg.score(X_test, y_test))\n",
    "y_pred = reg.predict(X_test)\n",
    "elapsed_time = time.time() - start_time\n",
    "print('elapsed time = ',elapsed_time )\n",
    "print('MSE = ',mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The model is fas but it has very poor performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing other Models:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now test several models including SGD, Gradient Boost, Random Forest and XGB and evaluate them base on mean squared error and performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_models():\n",
    "    \"\"\"\n",
    "    creates regression a selected models with the defualt values\n",
    "    \n",
    "    input :\n",
    "    ----\n",
    "    None\n",
    "    returns:\n",
    "    -------\n",
    "    Two lists, one for models and the second is for the name of the models\n",
    "    \"\"\"\n",
    "    sgd = SGDRegressor(random_state=2020)\n",
    "    grad = GradientBoostingRegressor(random_state=2020)\n",
    "    rf =RandomForestRegressor(random_state=2020)\n",
    "    xgb = XGBRegressor()\n",
    "    regressors = [sgd, grad,rf,xgb]\n",
    "    regressors_names = ['SGDRegressor','Gradient Boost','Random Forest','xgb']\n",
    "    return  regressors,regressors_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's test these models and evaluate their performance\n",
    "\n",
    "    \n",
    "regressors,regressor_names = build_models()\n",
    "\n",
    "for regressor,regressor_name in zip(regressors,regressor_names):\n",
    "    regressor_pipeline = Pipeline(steps = [('preprocessor',preprocessor),\n",
    "                                      ('regressor',regressor)])\n",
    "    start_time = time.time()\n",
    "    regressor_pipeline.fit(X_train,y_train)\n",
    "    print('Results for ',regressor_name)\n",
    "    print('Training score = ',regressor_pipeline.score(X_train,y_train))\n",
    "    print('Test score = ',regressor_pipeline.score(X_test,y_test))\n",
    "    y_pred = regressor_pipeline.predict(X_test)\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print('elapsed time = ',elapsed_time )\n",
    "    print('MSE = ',mean_squared_error(y_test, y_pred))\n",
    "    print('______________________________________________________')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### According to this results,we have the following observations :\n",
    "- Linear Regression SGDRegressor have the fastest models but also have the lowest accuracy\n",
    "- Gradient Boost model has the a bias issues, while random forest has a variance issues.\n",
    "- XGBRegressor seems to be the most promsing in terms of MSE. We will adopt this model and try to fine tune the paramters to improve the mse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Improvements : Hyperparamters optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's create our X_train and X_test since it has it's own cross-validation.\n",
    "data_train = xgboost.DMatrix(X_train, label=y_train)\n",
    "data_test = xgboost.DMatrix(X_test, label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will now create our initial set of paramters, which are the defual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    # Parameters that we are going to tune.\n",
    "    'max_depth':6,\n",
    "    'min_child_weight': 1,\n",
    "    'eta':.3,\n",
    "    'subsample': 1,\n",
    "    'colsample_bytree': 1,\n",
    "    # Other parameters\n",
    "    'objective':'reg:squarederror',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['eval_metric'] = \"rmse\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_boost_round = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tTest-rmse:5.55954\n",
      "Will train until Test-rmse hasn't improved in 10 rounds.\n",
      "[1]\tTest-rmse:5.32165\n",
      "[2]\tTest-rmse:5.17549\n",
      "[3]\tTest-rmse:5.09130\n",
      "[4]\tTest-rmse:5.02825\n",
      "[5]\tTest-rmse:4.99746\n",
      "[6]\tTest-rmse:4.97401\n",
      "[7]\tTest-rmse:4.94375\n",
      "[8]\tTest-rmse:4.93054\n",
      "[9]\tTest-rmse:4.92417\n",
      "[10]\tTest-rmse:4.91023\n",
      "[11]\tTest-rmse:4.89676\n",
      "[12]\tTest-rmse:4.89233\n",
      "[13]\tTest-rmse:4.88596\n",
      "[14]\tTest-rmse:4.87754\n",
      "[15]\tTest-rmse:4.87577\n",
      "[16]\tTest-rmse:4.85856\n",
      "[17]\tTest-rmse:4.85533\n",
      "[18]\tTest-rmse:4.85155\n",
      "[19]\tTest-rmse:4.83889\n",
      "[20]\tTest-rmse:4.83113\n",
      "[21]\tTest-rmse:4.82732\n",
      "[22]\tTest-rmse:4.82468\n",
      "[23]\tTest-rmse:4.81992\n",
      "[24]\tTest-rmse:4.81599\n",
      "[25]\tTest-rmse:4.81128\n",
      "[26]\tTest-rmse:4.80826\n",
      "[27]\tTest-rmse:4.80396\n",
      "[28]\tTest-rmse:4.80261\n",
      "[29]\tTest-rmse:4.80074\n",
      "[30]\tTest-rmse:4.79898\n",
      "[31]\tTest-rmse:4.79578\n",
      "[32]\tTest-rmse:4.79217\n",
      "[33]\tTest-rmse:4.79119\n",
      "[34]\tTest-rmse:4.78560\n",
      "[35]\tTest-rmse:4.78445\n",
      "[36]\tTest-rmse:4.78051\n",
      "[37]\tTest-rmse:4.77498\n",
      "[38]\tTest-rmse:4.76942\n",
      "[39]\tTest-rmse:4.76817\n",
      "[40]\tTest-rmse:4.76787\n",
      "[41]\tTest-rmse:4.76371\n",
      "[42]\tTest-rmse:4.76231\n",
      "[43]\tTest-rmse:4.76006\n",
      "[44]\tTest-rmse:4.75370\n",
      "[45]\tTest-rmse:4.75083\n",
      "[46]\tTest-rmse:4.74922\n",
      "[47]\tTest-rmse:4.74875\n",
      "[48]\tTest-rmse:4.74758\n",
      "[49]\tTest-rmse:4.74673\n",
      "[50]\tTest-rmse:4.74344\n",
      "[51]\tTest-rmse:4.74282\n",
      "[52]\tTest-rmse:4.74075\n",
      "[53]\tTest-rmse:4.73901\n",
      "[54]\tTest-rmse:4.73942\n",
      "[55]\tTest-rmse:4.73792\n",
      "[56]\tTest-rmse:4.73564\n",
      "[57]\tTest-rmse:4.73475\n",
      "[58]\tTest-rmse:4.73027\n",
      "[59]\tTest-rmse:4.72570\n",
      "[60]\tTest-rmse:4.72489\n",
      "[61]\tTest-rmse:4.72362\n",
      "[62]\tTest-rmse:4.72244\n",
      "[63]\tTest-rmse:4.71958\n",
      "[64]\tTest-rmse:4.71906\n",
      "[65]\tTest-rmse:4.71848\n",
      "[66]\tTest-rmse:4.71743\n",
      "[67]\tTest-rmse:4.71556\n",
      "[68]\tTest-rmse:4.71520\n",
      "[69]\tTest-rmse:4.71472\n",
      "[70]\tTest-rmse:4.71337\n",
      "[71]\tTest-rmse:4.71053\n",
      "[72]\tTest-rmse:4.71022\n",
      "[73]\tTest-rmse:4.71016\n",
      "[74]\tTest-rmse:4.70920\n",
      "[75]\tTest-rmse:4.70892\n",
      "[76]\tTest-rmse:4.70652\n",
      "[77]\tTest-rmse:4.70697\n",
      "[78]\tTest-rmse:4.70700\n",
      "[79]\tTest-rmse:4.70491\n",
      "[80]\tTest-rmse:4.70380\n",
      "[81]\tTest-rmse:4.70360\n",
      "[82]\tTest-rmse:4.70369\n",
      "[83]\tTest-rmse:4.70348\n",
      "[84]\tTest-rmse:4.70346\n",
      "[85]\tTest-rmse:4.70170\n",
      "[86]\tTest-rmse:4.70148\n",
      "[87]\tTest-rmse:4.69934\n",
      "[88]\tTest-rmse:4.69946\n",
      "[89]\tTest-rmse:4.69879\n",
      "[90]\tTest-rmse:4.69694\n",
      "[91]\tTest-rmse:4.69786\n",
      "[92]\tTest-rmse:4.69607\n",
      "[93]\tTest-rmse:4.69594\n",
      "[94]\tTest-rmse:4.69346\n",
      "[95]\tTest-rmse:4.69343\n",
      "[96]\tTest-rmse:4.69368\n",
      "[97]\tTest-rmse:4.69377\n",
      "[98]\tTest-rmse:4.69341\n",
      "[99]\tTest-rmse:4.69281\n",
      "[100]\tTest-rmse:4.69210\n",
      "[101]\tTest-rmse:4.69135\n",
      "[102]\tTest-rmse:4.69115\n",
      "[103]\tTest-rmse:4.68899\n",
      "[104]\tTest-rmse:4.68743\n",
      "[105]\tTest-rmse:4.68712\n",
      "[106]\tTest-rmse:4.68673\n",
      "[107]\tTest-rmse:4.68627\n",
      "[108]\tTest-rmse:4.68619\n",
      "[109]\tTest-rmse:4.68536\n",
      "[110]\tTest-rmse:4.68550\n",
      "[111]\tTest-rmse:4.68545\n",
      "[112]\tTest-rmse:4.68557\n",
      "[113]\tTest-rmse:4.68537\n",
      "[114]\tTest-rmse:4.68347\n",
      "[115]\tTest-rmse:4.68388\n",
      "[116]\tTest-rmse:4.68367\n",
      "[117]\tTest-rmse:4.68350\n",
      "[118]\tTest-rmse:4.68368\n",
      "[119]\tTest-rmse:4.68332\n",
      "[120]\tTest-rmse:4.68156\n",
      "[121]\tTest-rmse:4.68004\n",
      "[122]\tTest-rmse:4.67981\n",
      "[123]\tTest-rmse:4.67840\n",
      "[124]\tTest-rmse:4.67739\n",
      "[125]\tTest-rmse:4.67687\n",
      "[126]\tTest-rmse:4.67602\n",
      "[127]\tTest-rmse:4.67560\n",
      "[128]\tTest-rmse:4.67423\n",
      "[129]\tTest-rmse:4.67432\n",
      "[130]\tTest-rmse:4.67431\n",
      "[131]\tTest-rmse:4.67051\n",
      "[132]\tTest-rmse:4.67058\n",
      "[133]\tTest-rmse:4.67125\n",
      "[134]\tTest-rmse:4.67096\n",
      "[135]\tTest-rmse:4.67125\n",
      "[136]\tTest-rmse:4.66964\n",
      "[137]\tTest-rmse:4.66832\n",
      "[138]\tTest-rmse:4.66832\n",
      "[139]\tTest-rmse:4.66917\n",
      "[140]\tTest-rmse:4.66914\n",
      "[141]\tTest-rmse:4.66867\n",
      "[142]\tTest-rmse:4.66891\n",
      "[143]\tTest-rmse:4.66743\n",
      "[144]\tTest-rmse:4.66689\n",
      "[145]\tTest-rmse:4.66703\n",
      "[146]\tTest-rmse:4.66721\n",
      "[147]\tTest-rmse:4.66683\n",
      "[148]\tTest-rmse:4.66627\n",
      "[149]\tTest-rmse:4.66622\n",
      "[150]\tTest-rmse:4.66641\n",
      "[151]\tTest-rmse:4.66616\n",
      "[152]\tTest-rmse:4.66629\n",
      "[153]\tTest-rmse:4.66577\n",
      "[154]\tTest-rmse:4.66491\n",
      "[155]\tTest-rmse:4.66456\n",
      "[156]\tTest-rmse:4.66459\n",
      "[157]\tTest-rmse:4.66369\n",
      "[158]\tTest-rmse:4.66187\n",
      "[159]\tTest-rmse:4.66257\n",
      "[160]\tTest-rmse:4.66238\n",
      "[161]\tTest-rmse:4.66242\n",
      "[162]\tTest-rmse:4.66212\n",
      "[163]\tTest-rmse:4.66185\n",
      "[164]\tTest-rmse:4.66233\n",
      "[165]\tTest-rmse:4.66321\n",
      "[166]\tTest-rmse:4.66353\n",
      "[167]\tTest-rmse:4.66184\n",
      "[168]\tTest-rmse:4.66203\n",
      "[169]\tTest-rmse:4.66189\n",
      "[170]\tTest-rmse:4.66101\n",
      "[171]\tTest-rmse:4.66154\n",
      "[172]\tTest-rmse:4.66154\n",
      "[173]\tTest-rmse:4.66136\n",
      "[174]\tTest-rmse:4.66118\n",
      "[175]\tTest-rmse:4.66018\n",
      "[176]\tTest-rmse:4.66049\n",
      "[177]\tTest-rmse:4.65961\n",
      "[178]\tTest-rmse:4.65974\n",
      "[179]\tTest-rmse:4.65973\n",
      "[180]\tTest-rmse:4.65981\n",
      "[181]\tTest-rmse:4.66004\n",
      "[182]\tTest-rmse:4.65995\n",
      "[183]\tTest-rmse:4.65991\n",
      "[184]\tTest-rmse:4.65862\n",
      "[185]\tTest-rmse:4.65897\n",
      "[186]\tTest-rmse:4.65811\n",
      "[187]\tTest-rmse:4.65833\n",
      "[188]\tTest-rmse:4.65831\n",
      "[189]\tTest-rmse:4.65860\n",
      "[190]\tTest-rmse:4.65858\n",
      "[191]\tTest-rmse:4.65823\n",
      "[192]\tTest-rmse:4.65825\n",
      "[193]\tTest-rmse:4.65852\n",
      "[194]\tTest-rmse:4.65675\n",
      "[195]\tTest-rmse:4.65668\n",
      "[196]\tTest-rmse:4.65664\n",
      "[197]\tTest-rmse:4.65726\n",
      "[198]\tTest-rmse:4.65721\n",
      "[199]\tTest-rmse:4.65773\n",
      "[200]\tTest-rmse:4.65637\n",
      "[201]\tTest-rmse:4.65625\n",
      "[202]\tTest-rmse:4.65476\n",
      "[203]\tTest-rmse:4.65511\n",
      "[204]\tTest-rmse:4.65497\n",
      "[205]\tTest-rmse:4.65442\n",
      "[206]\tTest-rmse:4.65411\n",
      "[207]\tTest-rmse:4.65341\n",
      "[208]\tTest-rmse:4.65370\n",
      "[209]\tTest-rmse:4.65428\n",
      "[210]\tTest-rmse:4.65349\n",
      "[211]\tTest-rmse:4.65318\n",
      "[212]\tTest-rmse:4.65294\n",
      "[213]\tTest-rmse:4.65329\n",
      "[214]\tTest-rmse:4.65342\n",
      "[215]\tTest-rmse:4.65315\n",
      "[216]\tTest-rmse:4.65321\n",
      "[217]\tTest-rmse:4.65386\n",
      "[218]\tTest-rmse:4.65394\n",
      "[219]\tTest-rmse:4.65436\n",
      "[220]\tTest-rmse:4.65480\n",
      "[221]\tTest-rmse:4.65447\n",
      "[222]\tTest-rmse:4.65383\n",
      "Stopping. Best iteration:\n",
      "[212]\tTest-rmse:4.65294\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = xgboost.train(\n",
    "    params,\n",
    "    data_train,\n",
    "    num_boost_round=num_boost_round,\n",
    "    evals=[(data_test, \"Test\")],\n",
    "    early_stopping_rounds=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's perform cross validation using the built in funciton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = xgboost.cv(\n",
    "    params,\n",
    "    data_train,\n",
    "    num_boost_round=num_boost_round,\n",
    "    seed=2020,\n",
    "    nfold=10,\n",
    "    metrics={'rmse'},\n",
    "    early_stopping_rounds=20\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train-rmse-mean</th>\n",
       "      <th>train-rmse-std</th>\n",
       "      <th>test-rmse-mean</th>\n",
       "      <th>test-rmse-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.544535</td>\n",
       "      <td>0.005901</td>\n",
       "      <td>5.549616</td>\n",
       "      <td>0.059906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.306300</td>\n",
       "      <td>0.006526</td>\n",
       "      <td>5.316954</td>\n",
       "      <td>0.058216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.157468</td>\n",
       "      <td>0.006689</td>\n",
       "      <td>5.171986</td>\n",
       "      <td>0.055148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.069151</td>\n",
       "      <td>0.006889</td>\n",
       "      <td>5.088351</td>\n",
       "      <td>0.055494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.010549</td>\n",
       "      <td>0.007095</td>\n",
       "      <td>5.035326</td>\n",
       "      <td>0.053641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>3.942795</td>\n",
       "      <td>0.012129</td>\n",
       "      <td>4.667424</td>\n",
       "      <td>0.058483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>3.941149</td>\n",
       "      <td>0.012147</td>\n",
       "      <td>4.667588</td>\n",
       "      <td>0.058322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>3.939369</td>\n",
       "      <td>0.012376</td>\n",
       "      <td>4.667427</td>\n",
       "      <td>0.058150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>3.937337</td>\n",
       "      <td>0.012343</td>\n",
       "      <td>4.667178</td>\n",
       "      <td>0.058254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>3.935495</td>\n",
       "      <td>0.011716</td>\n",
       "      <td>4.666933</td>\n",
       "      <td>0.058421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>293 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     train-rmse-mean  train-rmse-std  test-rmse-mean  test-rmse-std\n",
       "0           5.544535        0.005901        5.549616       0.059906\n",
       "1           5.306300        0.006526        5.316954       0.058216\n",
       "2           5.157468        0.006689        5.171986       0.055148\n",
       "3           5.069151        0.006889        5.088351       0.055494\n",
       "4           5.010549        0.007095        5.035326       0.053641\n",
       "..               ...             ...             ...            ...\n",
       "288         3.942795        0.012129        4.667424       0.058483\n",
       "289         3.941149        0.012147        4.667588       0.058322\n",
       "290         3.939369        0.012376        4.667427       0.058150\n",
       "291         3.937337        0.012343        4.667178       0.058254\n",
       "292         3.935495        0.011716        4.666933       0.058421\n",
       "\n",
       "[293 rows x 4 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.780264559875615"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results['test-rmse-mean'].min()**2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tunning paramters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters max_depth and min_child_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch_params = [\n",
    "    (max_depth, min_child_weight)\n",
    "    for max_depth in range(3,15)\n",
    "    for min_child_weight in range(1,4)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV with max_depth=3, min_child_weight=1\n"
     ]
    }
   ],
   "source": [
    "#Define initial best params and MAE\n",
    "min_rmse = float(\"Inf\")\n",
    "best_params = None\n",
    "for max_depth, min_child_weight in gridsearch_params:\n",
    "    print(\"CV with max_depth={}, min_child_weight={}\".format(\n",
    "                             max_depth,\n",
    "                             min_child_weight))\n",
    "    # Update our parameters\n",
    "    params['max_depth'] = max_depth\n",
    "    params['min_child_weight'] = min_child_weight\n",
    "    # Run CV\n",
    "    cv_results = xgboost.cv(\n",
    "        params,\n",
    "        data_train,\n",
    "        num_boost_round=num_boost_round,\n",
    "        seed=42,\n",
    "        nfold=10,\n",
    "        metrics={'rmse'},\n",
    "        early_stopping_rounds=10\n",
    "    )\n",
    "    # Update best MAE\n",
    "    mean_rmse = cv_results['test-rmse-mean'].min()\n",
    "    boost_rounds = cv_results['test-rmse-mean'].argmin()\n",
    "    print(\"\\trmse {} for {} rounds\".format(mean_rmse, boost_rounds))\n",
    "    if mean_rmse < min_rmse:\n",
    "        min_rmse = mean_rmse\n",
    "        best_params = (max_depth,min_child_weight)\n",
    "print(\"Best params: {}, {}, RMSE: {}\".format(best_params[0], best_params[1], min_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['max_depth'] = 3\n",
    "params['min_child_ weight'] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters subsample and colsample_bytree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch_params = [\n",
    "    (subsample, colsample)\n",
    "    for subsample in [i/10. for i in range(7,11)]\n",
    "    for colsample in [i/10. for i in range(7,11)]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_mae = float(\"Inf\")\n",
    "best_params = None\n",
    "# We start by the largest values and go down to the smallest\n",
    "for subsample, colsample in reversed(gridsearch_params):\n",
    "    print(\"CV with subsample={}, colsample={}\".format(\n",
    "                             subsample,\n",
    "                             colsample))\n",
    "    # We update our parameters\n",
    "    params['subsample'] = subsample\n",
    "    params['colsample_bytree'] = colsample\n",
    "    # Run CV\n",
    "    cv_results = xgboost.cv(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=num_boost_round,\n",
    "        seed=42,\n",
    "        nfold=5,\n",
    "        metrics={'rmse'},\n",
    "        early_stopping_rounds=10\n",
    "    )\n",
    "    # Update best score\n",
    "    mean_mae = cv_results['test-rmse-mean'].min()\n",
    "    boost_rounds = cv_results['test-rmse-mean'].argmin()\n",
    "    print(\"\\tMAE {} for {} rounds\".format(mean_mae, boost_rounds))\n",
    "    if mean_mae < min_mae:\n",
    "        min_mae = mean_mae\n",
    "        best_params = (subsample,colsample)\n",
    "print(\"Best params: {}, {}, MAE: {}\".format(best_params[0], best_params[1], min_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['subsample'] = 0.9\n",
    "params['colsample_bytree'] = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameter ETA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "# This can take some time…\n",
    "min_mae = float(\"Inf\")\n",
    "best_params = None\n",
    "for eta in [.3, .2, .1, .05, .01, .005]:\n",
    "    print(\"CV with eta={}\".format(eta))\n",
    "    # We update our parameters\n",
    "    params['eta'] = eta\n",
    "    # Run and time CV\n",
    "    %time cv_results = xgboost.cv(params,dtrain,num_boost_round=num_boost_round,seed=42,nfold=5,metrics=['rmse'],early_stopping_rounds=10)\n",
    "    # Update best score\n",
    "    mean_mae = cv_results['test-rmse-mean'].min()\n",
    "    boost_rounds = cv_results['test-rmse-mean'].argmin()\n",
    "    print(\"\\tMAE {} for {} rounds\\n\".format(mean_mae, boost_rounds))\n",
    "    if mean_mae < min_mae:\n",
    "        min_mae = mean_mae\n",
    "        best_params = eta\n",
    "print(\"Best params: {}, MAE: {}\".format(best_params, min_mae))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['eta'] = .03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at out final parameters\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = xgboost.cv(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=num_boost_round,\n",
    "    seed=42,\n",
    "    nfold=5,\n",
    "    metrics={'rmse'},\n",
    "    early_stopping_rounds=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results['test-rmse-mean'].min()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training the final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgboost.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=num_boost_round,\n",
    "    evals=[(dtest, \"Test\")],\n",
    "    early_stopping_rounds=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_boost_round = model.best_iteration + 1\n",
    "best_model = xgboost.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=num_boost_round,\n",
    "    evals=[(dtest, \"Test\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(best_model.predict(dtest), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
